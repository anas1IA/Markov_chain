{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8412,
          "sourceType": "datasetVersion",
          "datasetId": 5637
        }
      ],
      "dockerImageVersionId": 30035,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anas1IA/Markov_chain/blob/main/markov_chain_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&amp;id=1zSJwAUxWv5bxyYLmYPNi-s6M_Wq5iWXh\">"
      ],
      "metadata": {
        "id": "C5W5QPnJN689"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing tools"
      ],
      "metadata": {
        "id": "d9FhrvsiN69L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "qnzFzKFuN69N"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the homles.zip file\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "PkwHeJzaTFDQ",
        "outputId": "8adf531a-b33d-4891-9553-ba5ff82a3270"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-938bbd7d-7e3c-4f3e-bd69-d760ea1ec7e4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-938bbd7d-7e3c-4f3e-bd69-d760ea1ec7e4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the homles.zip file\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "tn3JYEsOTny2",
        "outputId": "96e89119-e1aa-4d68-874e-2eb25d01a5fd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f9a050c0-bb8f-4e7e-9ad4-62bb8ca65d46\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f9a050c0-bb8f-4e7e-9ad4-62bb8ca65d46\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = \"homles.zip\"\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extracted_dir_path = \"my_directory\"\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "os.makedirs(extracted_dir_path, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "# List the contents of the extracted directory\n",
        "extracted_files = os.listdir(extracted_dir_path)\n",
        "print(\"Extracted files:\", extracted_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--fQD9v-Vrzo",
        "outputId": "9f6c0826-8186-46c8-ada6-48b1dfb5ac7c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['sherlock']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir my_directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltKcDr6GResX",
        "outputId": "075d392a-8ea5-421f-fafd-6608dcec24ff"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘my_directory’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading every Sherlock Holmes adventure!"
      ],
      "metadata": {
        "id": "v-klW2M0N69S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story_path = \"my_directory/sherlock/sherlock/\"\n",
        "\n",
        "def read_all_stories(story_path):\n",
        "    txt = []\n",
        "    for _, _, files in os.walk(story_path):\n",
        "        for file in files:\n",
        "            with open(story_path+file) as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line=='----------': break\n",
        "                    if line!='':txt.append(line)\n",
        "    return txt\n",
        "\n",
        "stories = read_all_stories(story_path)\n",
        "print(\"number of lines = \", len(stories))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Lzp9p0N69T",
        "outputId": "e62ea721-2494-45ce-d60b-6cb188e4e43c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of lines =  215021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download the 'punkt' resource\n",
        "nltk.download('punkt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uOarDAbZqCC",
        "outputId": "50dd9f5a-f389-43f6-8af5-e5b11685cabe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the text"
      ],
      "metadata": {
        "id": "vB2uXVufN69X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_txt(txt):\n",
        "    cleaned_txt = []\n",
        "    for line in txt:\n",
        "        line = line.lower()\n",
        "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "        tokens = word_tokenize(line)\n",
        "        words = [word for word in tokens if word.isalpha()]\n",
        "        cleaned_txt+=words\n",
        "    return cleaned_txt\n",
        "\n",
        "cleaned_stories = clean_txt(stories)\n",
        "print(\"number of words = \", len(cleaned_stories))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSV6v4TqN69Y",
        "outputId": "507518f5-1fd7-41b9-941d-0517bfbad655"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words =  2332247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Markov Model"
      ],
      "metadata": {
        "id": "HDMnPTa6N69a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):\n",
        "    markov_model = {}\n",
        "    for i in range(len(cleaned_stories)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i+j] + \" \"\n",
        "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "\n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "\n",
        "    return markov_model"
      ],
      "metadata": {
        "trusted": true,
        "id": "V0o1JaMON69b"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = make_markov_model(cleaned_stories)"
      ],
      "metadata": {
        "trusted": true,
        "id": "DcQ5ttEVN69d"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of states = \", len(markov_model.keys()))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da2GZgFHN69e",
        "outputId": "3abf5b45-0d9b-4945-ee53-b7c402d2f61d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of states =  208715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All possible transitions from 'my own' state: \\n\")\n",
        "print(markov_model['my own'])"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dumr4tDN69f",
        "outputId": "2f6ee278-1ecf-4be6-b963-531b331c13d0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All possible transitions from 'my own' state: \n",
            "\n",
            "{'pursuit a': 0.005063291139240506, 'mind for': 0.005063291139240506, 'part i': 0.010126582278481013, 'way is': 0.0037974683544303796, 'hearth smoking': 0.005063291139240506, 'mind i': 0.005063291139240506, 'accord but': 0.005063291139240506, 'experience it': 0.0037974683544303796, 'professional eye': 0.0037974683544303796, 'room and': 0.0037974683544303796, 'perhaps i': 0.0037974683544303796, 'performances a': 0.0037974683544303796, 'affairs needed': 0.0037974683544303796, 'devices there': 0.0037974683544303796, 'game and': 0.007594936708860759, 'bedroom he': 0.0037974683544303796, 'against him': 0.0037974683544303796, 'story it': 0.0037974683544303796, 'story i': 0.0037974683544303796, 'face is': 0.005063291139240506, 'sake but': 0.008860759493670886, 'insignificant personality': 0.0037974683544303796, 'what were': 0.0037974683544303796, 'idea of': 0.0037974683544303796, 'way and': 0.0037974683544303796, 'time complete': 0.0037974683544303796, 'her sad': 0.0037974683544303796, 'that is': 0.0037974683544303796, 'and it': 0.0037974683544303796, 'ideas until': 0.0037974683544303796, 'my luck': 0.0037974683544303796, 'no one': 0.0037974683544303796, 'good reasons': 0.0037974683544303796, 'shack there': 0.0037974683544303796, 'for the': 0.0037974683544303796, 'time mister': 0.0037974683544303796, 'time in': 0.0037974683544303796, 'way tut': 0.0037974683544303796, 'name youve': 0.0037974683544303796, 'eminent bodymaster': 0.0037974683544303796, 'bedroom with': 0.0037974683544303796, 'way i': 0.008860759493670886, 'lodge if': 0.0037974683544303796, 'blunder we': 0.005063291139240506, 'good at': 0.005063291139240506, 'views are': 0.010126582278481013, 'credit to': 0.005063291139240506, 'observation there': 0.005063291139240506, 'hands i': 0.005063291139240506, 'sister but': 0.005063291139240506, 'street and': 0.005063291139240506, 'master and': 0.005063291139240506, 'terms im': 0.005063291139240506, 'heart grew': 0.005063291139240506, 'in many': 0.005063291139240506, 'name is': 0.005063291139240506, 'sight had': 0.005063291139240506, 'voice but': 0.005063291139240506, 'hand in': 0.005063291139240506, 'worst blunders': 0.005063291139240506, 'agents i': 0.005063291139240506, 'i reckon': 0.0037974683544303796, 'impression was': 0.0037974683544303796, 'mistress for': 0.0037974683544303796, 'business said': 0.0037974683544303796, 'eyes and': 0.0037974683544303796, 'mind all': 0.0037974683544303796, 'i suppose': 0.0037974683544303796, 'eyes you': 0.0037974683544303796, 'hook i': 0.0037974683544303796, 'comrades hacked': 0.0037974683544303796, 'some of': 0.0037974683544303796, 'eyes i': 0.008860759493670886, 'mind were': 0.0037974683544303796, 'arrangements but': 0.0037974683544303796, 'combinations i': 0.0037974683544303796, 'darling in': 0.0037974683544303796, 'life is': 0.0037974683544303796, 'mind what': 0.0037974683544303796, 'hands dont': 0.0037974683544303796, 'face who': 0.0037974683544303796, 'blood and': 0.0037974683544303796, 'secrets he': 0.0037974683544303796, 'mind that': 0.0037974683544303796, 'proper atmosphere': 0.0037974683544303796, 'particular profession': 0.0037974683544303796, 'limited knowledge': 0.0037974683544303796, 'liking an': 0.0037974683544303796, 'servant could': 0.0037974683544303796, 'i wish': 0.0037974683544303796, 'eyes our': 0.0037974683544303796, 'life away': 0.0037974683544303796, 'complete happiness': 0.005063291139240506, 'his manner': 0.005063291139240506, 'i was': 0.005063291139240506, 'person yet': 0.005063291139240506, 'seal imitated': 0.005063291139240506, 'arrangements which': 0.005063291139240506, 'station what': 0.005063291139240506, 'little adventures': 0.005063291139240506, 'and that': 0.005063291139240506, 'good fortune': 0.005063291139240506, 'stupidity in': 0.005063291139240506, 'to settle': 0.005063291139240506, 'right besides': 0.005063291139240506, 'attention at': 0.005063291139240506, 'master you': 0.005063291139240506, 'head clearly': 0.005063291139240506, 'roof than': 0.005063291139240506, 'fate was': 0.005063291139240506, 'family you': 0.005063291139240506, 'affairs have': 0.005063291139240506, 'police when': 0.005063291139240506, 'purposes and': 0.005063291139240506, 'thoughts are': 0.005063291139240506, 'income and': 0.005063291139240506, 'there is': 0.005063291139240506, 'thought is': 0.005063291139240506, 'province this': 0.005063291139240506, 'services and': 0.005063291139240506, 'heart she': 0.005063291139240506, 'curiosity it': 0.005063291139240506, 'marriage during': 0.005063291139240506, 'memory lord': 0.005063291139240506, 'case i': 0.005063291139240506, 'private purse': 0.005063291139240506, 'bureau well': 0.005063291139240506, 'way in': 0.005063291139240506, 'eyes with': 0.005063291139240506, 'son do': 0.005063291139240506, 'little practice': 0.005063291139240506, 'special subject': 0.005063291139240506, 'room which': 0.005063291139240506, 'shadow might': 0.005063291139240506, 'little things': 0.005063291139240506, 'hair i': 0.005063291139240506, 'methods and': 0.005063291139240506, 'mind how': 0.005063291139240506, 'judgment to': 0.005063291139240506, 'dear little': 0.005063291139240506, 'little girl': 0.005063291139240506, 'youth and': 0.005063291139240506, 'little methods': 0.005063291139240506, 'age i': 0.005063291139240506, 'to do': 0.005063291139240506, 'arrest he': 0.005063291139240506, 'free will': 0.005063291139240506, 'hobby has': 0.005063291139240506, 'college career': 0.005063291139240506, 'praises if': 0.005063291139240506, 'nervous system': 0.005063291139240506, 'to each': 0.005063291139240506, 'clumsiness he': 0.005063291139240506, 'was at': 0.005063291139240506, 'career had': 0.005063291139240506, 'voice reverberating': 0.005063291139240506, 'private satisfaction': 0.005063291139240506, 'eyes that': 0.005063291139240506, 'most vindictive': 0.005063291139240506, 'person at': 0.005063291139240506, 'old room': 0.005063291139240506, 'sad bereavement': 0.005063291139240506, 'senses as': 0.005063291139240506, 'photograph she': 0.005063291139240506, 'line and': 0.005063291139240506, 'safety that': 0.005063291139240506, 'inclination is': 0.005063291139240506, 'lines and': 0.005063291139240506, 'she broke': 0.005063291139240506, 'part the': 0.005063291139240506, 'inclinations are': 0.005063291139240506, 'doorstep as': 0.005063291139240506, 'counter do': 0.005063291139240506, 'there but': 0.005063291139240506, 'i am': 0.008860759493670886, 'it rather': 0.005063291139240506, 'conscience let': 0.005063291139240506, 'ideas were': 0.005063291139240506, 'mind is': 0.005063291139240506, 'small way': 0.005063291139240506, 'small achievements': 0.0037974683544303796, 'come come': 0.0037974683544303796, 'obvious interest': 0.0037974683544303796, 'account i': 0.0037974683544303796, 'affairs you': 0.0037974683544303796, 'people and': 0.0037974683544303796, 'was busy': 0.0037974683544303796, 'he got': 0.0037974683544303796, 'was in': 0.0037974683544303796, 'misfortune for': 0.0037974683544303796, 'letters to': 0.0037974683544303796, 'mind it': 0.0037974683544303796, 'ears heard': 0.0037974683544303796, 'steps to': 0.0037974683544303796, 'end we': 0.0037974683544303796, 'lips he': 0.0037974683544303796, 'experience for': 0.0037974683544303796, 'eyes the': 0.0037974683544303796, 'plan as': 0.0037974683544303796, 'fingers smouldered': 0.0037974683544303796, 'name to': 0.0037974683544303796, 'experience depended': 0.0037974683544303796, 'observations by': 0.0037974683544303796, 'rooms in': 0.0037974683544303796, 'and i': 0.0037974683544303796, 'but i': 0.0037974683544303796, 'hand is': 0.0037974683544303796, 'adventure the': 0.0037974683544303796, 'treasures and': 0.0037974683544303796, 'way of': 0.0037974683544303796, 'humdrum fashion': 0.0037974683544303796, 'chronicler ah': 0.0037974683544303796, 'plain way': 0.0037974683544303796, 'way by': 0.0037974683544303796, 'son he': 0.0037974683544303796, 'you know': 0.0037974683544303796, 'the irregulars': 0.0037974683544303796}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Sherlock Holmes stories!"
      ],
      "metadata": {
        "id": "laXUk9xpN69f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(markov_model, limit=100, start='my god'):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story+=curr_state+\" \"\n",
        "    while n<limit:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "\n",
        "        curr_state = next_state[0]\n",
        "        story+=curr_state+\" \"\n",
        "        n+=1\n",
        "    return story"
      ],
      "metadata": {
        "trusted": true,
        "id": "PE5pD6cEN69g"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"dear holmes\", limit=8))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4MN8Z6KN69g",
        "outputId": "d49cb99f-268d-438c-a453-af6b4175b1ef"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  dear holmes oh yes with the strange business which would have been aware of a pair you should \n",
            "1.  dear holmes am i he gazed about him when i came to see him then she threw open \n",
            "2.  dear holmes what do you make of that which he himself possesses the fame of your game you \n",
            "3.  dear holmes oh yes sir i shall be most happy to look for help as we moved across \n",
            "4.  dear holmes he has acted from motives which are not a married woman grabs at her back she \n",
            "5.  dear holmes said i as i remarked before that holmes i had taken over with the roof and \n",
            "6.  dear holmes i thought there might be some very different level to your majesty there is a by \n",
            "7.  dear holmes oh yes no doubt but he attacks no one else suppose i try my luck upon \n",
            "8.  dear holmes if i had put his money if this were the plans in that safe von bork \n",
            "9.  dear holmes and tell me that it was that gaunt wasted face staring at it in my own \n",
            "10.  dear holmes said i my dear fellow we called baldy simpson and these gypsies i have also had \n",
            "11.  dear holmes my previous letters and is now past the west india docks down the long run what \n",
            "12.  dear holmes he has twice lodged at tavistock in the paper next morning the womans story hung coherently \n",
            "13.  dear holmes he has a under his arm down to the station inn and the house with three \n",
            "14.  dear holmes it is not ours where is the old man and also of a pretty mess youve \n",
            "15.  dear holmes he has gone upon a voyage round the curve of the drive inspecting a bicycle which \n",
            "16.  dear holmes what do you allow that we were indeed very close a connection after all it is \n",
            "17.  dear holmes i exclaimed and this time it seemed from comparing notes afterwards it was but a lurid \n",
            "18.  dear holmes i exclaimed you here the same idea so does the idiot do but get into the \n",
            "19.  dear holmes it is impossible for me to do so i thought he might have communicated with his \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"my dear\", limit=8))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3V6lnX4N69h",
        "outputId": "6db725cd-dc4b-4ed6-81d7-965f0b218a2d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  my dear friend stood i know so why when we got there but you look weary yes the \n",
            "1.  my dear wife died i felt strongly that neither the country nor the sea air sunshine and patience \n",
            "2.  my dear fellow you will need your handcuffs inspector you are at your service there have come to \n",
            "3.  my dear watson said holmes with an air of displeasure her brother are the aborigines of the andaman \n",
            "4.  my dear watson said he coolly when a few weeks before my own marriage during the night a \n",
            "5.  my dear watson but the colonels face it had set himself to uncongenial silence staring moodily out of \n",
            "6.  my dear holmes am i right barker beat his head which had evidently been in his right hand \n",
            "7.  my dear watson should realize said barker quickly as he was sent a convict to siberia where now \n",
            "8.  my dear mr mac said he drop it because he foresaw that she would have forgiven me she \n",
            "9.  my dear fellow he hardly knew what he was going to say to you and that the stains \n",
            "10.  my dear daughter alice now in his fifth year and he owns a greuze well surely the inference \n",
            "11.  my dear fellow you know my methods of work in this business better in consequence we are four \n",
            "12.  my dear watson if we could conceal ourselves and see what comes of it the fact that i \n",
            "13.  my dear sir cried the king employed an agent it might have reached your ears holmes shot out \n",
            "14.  my dear holmes i think i did but how do you deduce the telegram was a new shoe \n",
            "15.  my dear madam said holmes though the matter stands i realize that my liberty the situation said he \n",
            "16.  my dear watson you will call upon him for on the endowment house there was some reflection on \n",
            "17.  my dear watson and a good fire and the room and seen dorak suave person bohemian elderly keeps \n",
            "18.  my dear fellow it is nearly all london who loves art for its own reward if you will \n",
            "19.  my dear watson i could not harm us they had dragged the basin of trafalgar square he said \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"i would\", limit=8))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NsOvrImN69i",
        "outputId": "a733e6f0-fd01-4007-ad58-ee03f6b423b6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  i would have gone on after receiving such an injury so lightly that it was in march a \n",
            "1.  i would have swung for him and his identity had been a convict these few indications but they \n",
            "2.  i would i could discern no others sherlock holmes struck a match and in the tails of the \n",
            "3.  i would always be associated in my mind that i could find where he went to bed my \n",
            "4.  i would do what you think such a very natural hum think of her crime for which he \n",
            "5.  i would but that nothing had been done to dispose of those damned touts cried the older man \n",
            "6.  i would go said she trying hard as it seemed that the good zeppelin promises us comes true \n",
            "7.  i would have you not dad she asked so roguish and exquisite did she speak to him about \n",
            "8.  i would suggest for example that some murder has been trampled up a good many cases but i \n",
            "9.  i would ask you where is that friend hopkins will live up to his brother which he handed \n",
            "10.  i would have shown that his brother officer was in our room its very annoying though watson i \n",
            "11.  i would stand by me and i had seldom known a case against the glare well and what \n",
            "12.  i would go round at night to the clothes which hung so baggily over his shrivelled limbs proclaimed \n",
            "13.  i would not venture to express my gratitude mr pinner said i i have an important secret as \n",
            "14.  i would pay ten that would fully explain the facts came out strengthened the supposition and i examined \n",
            "15.  i would not suggest and bring him back with a certain miss maud bellamy will always secure me \n",
            "16.  i would come back to his sympathies while he would return the second is to clear up it \n",
            "17.  i would have told you that it means no good but would only throw my own private satisfaction \n",
            "18.  i would have allowed anyone to pass through as you surveyed the room in little circles like a \n",
            "19.  i would marry the young duke of lomond who might be of any use to your and that \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_story(markov_model, start=\"the case\", limit=100))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUyrfRDxN69j",
        "outputId": "f0e59104-b645-42bb-fa85-000ffaae113a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the case is as much a departure from truth as i am ready said he there are several points in it which showed an eccentricity and irregularity in his life recently had not been drawn so that i had a chance the moon broke through the paper that lay before me but by gar if i fail i have other things to attend to will you not show you the different steps in my mind to leave a permanent weakness you know of it holmes was always of use and the rest was inconceivable you can to the morality or decency of your conduct has been here i will turn the facts which formed one of your boots although used are by no means god bless you for some weeks must elapse before we start i lay back in his purse but your other boot no sir it didnt matter to me most desperately at last he professed himself satisfied and with a very fashionably dressed and stayed for half wages it was obvious that the most powerful and richest organizations in this state that will do said mcmurdo then why did you not to do miss morstan he asked not at \n"
          ]
        }
      ]
    }
  ]
}